---
title: "Flow Modeling Approaches"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{flow_modeling_approaches}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, fig.width=15, fig.height=30)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(streamFlowExplorer)
library(CDECRetrieve)
library(dplyr)

colors <- c("#326875", "#899da4", "#9ab293", "#c1c172")
colors_small <- c("#326875", "#c1c172")
```

Some sources to review
- https://www.sciencedirect.com/science/article/abs/pii/S0022169418309648



# Introduction

Flow data modeling is crucial for various applications in hydrology, water resource management, and environmental studies. In cases where empirical data for a stream is lacking, several approaches can be employed to generate flow estimates. In this document, we explore various methods for modeling flow data when empirical data is unavailable.


## Approach 1: Timeserries interpretation 

**Benefit:** Quick and easy, performs relatively well for flow data that follows seasonal patterns. Good for data that is fairly complete with some shorter gaps. 
**Limitation:** May miss abnormal extreme flow events, may have more uncertainty than other approaches 

Using a timeserries interpolation function is a good approach if you have relatively good data coverage but have a few data gaps. One possible interpolation function is the `forecastML::fill_gaps()`. For more information about this function, see the [forecastML documenation.](https://rdrr.io/cran/forecastML/man/fill_gaps.html)

### Example

I want to study the flow and temperature correlation on ___ system. There is a USGS gage on my system, but it is missing data for _____ window.  

```{r}
# Load necessary libraries
library(dataRetrieval)
library(forecastML)
library(forecast)
# Make API call to CDEC to retrieve flow data for the specified site and time period
amk <- cdec_query(station = "AMK", dur_code = "H", sensor_num = "20", start_date = "2017-01-01") |>
  mutate(date = as_date(datetime)) |> 
  group_by(date) |> 
  summarise(flow_cfs = mean(parameter_value, na.rm = TRUE)) |> 
  # filter(!is.na(date), !is.na(flow_cfs)) |> 
  mutate(data_type = "gage")

# Plot original and filled data for comparison
amk |> 
  ggplot(aes(x = date, y = flow_cfs, color = data_type)) + 
  geom_line() + 
  scale_color_manual(values = colors_small) +
  theme_minimal()
# 'gage_data' is the dataset containing CDEC flow data with gaps
# Fill gaps in flow data using interpolation function 
# Search to find the right interpolation function 
# Start with forcast::forecast() before so that might be better 
# if that doesn't work use this one - `forecastML::fill_gaps()` is one option 
# And then update documentation above to show which forecast function you are using 
# Remove rows with NA in the "date" column


#create a timeseries that covers all dates of date period

```


## Approach 2: Linear Regression between Stream Gage Data - Filling a temporal data gap 

**Benefit:** Fairly quick and straightforward, linear regression typically does a fairly good job
**Limitation:** Need at least some gage overlap across different conditions, if you do not have good coverage across different conditions you may loose some of the extreem flow events 

One approach is to interpolate flow data for one stream using available stream gage data. In order to do this you need at least some gage data on the system you are trying to model and this data should cover a variety of conditions (water year types). This method establishes a linear correlation between the target site and other sites that experience similar hydrological conditions. The approach requires identifying comparable sites and establishing a relationship between their flow data.

### Example

I am creating a regional model with data from 4 salmonid bearing streams: Butte Creek, Mill Creek, Deer Creek, and Yuba River . I am interested in flow data from 2000 - 2024 to match with my monitoring data. Unfortunately, on Yuba River, there is only gage data after 2010. In order to keep Yuba in my dataset. I need to fill in the gaps. 

```{r}
## Data used to build models: Butte Creek
# Butte Creek is used to build the regression models because the time series is complete and the data are high quality.
#data range 1997-03-12 to 2024-03-20
cdec_datasets("BCK")
butte <- cdec_query(station = "BCK", dur_code = "H", sensor_num = "20", start_date = "1997-01-01")
butte_format <- butte |> 
    mutate(date = as_date(datetime),
           flow = parameter_value) |>
  filter(parameter_value > 0) |> 
    group_by(date) |> 
    summarise(mean = mean(parameter_value, na.rm = TRUE),
              max = max(parameter_value, na.rm = TRUE),
              min = min(parameter_value, na.rm = TRUE)) |> 
    pivot_longer(mean:min, names_to = "statistic", values_to = "value") |>
    mutate(stream = "butte creek",
           gage_agency = "CDEC",
           gage_number = "BCK",
           parameter = "flow") |> 
  glimpse() 

butte_format_wide <- butte_format |> 
  ungroup() |> 
  select(-gage_agency, -gage_number) |> 
  pivot_wider(id_cols = c(stream, date), names_from = "statistic", values_from = "value", values_fill = NA) |> 
  glimpse()

ggplot(butte_format, aes(x = date, y = value)) +
  geom_line()


#gage option 1 
cdec_datasets("YPB") 
# 2010-10-01	2024-03-20
# Gage Data
YR7_daily_flows <- cdec_query(station = "YPB", dur_code = "H", sensor_num = "20", start_date = "2009-01-01")

yuba_format <- YR7_daily_flows |> 
    mutate(date = as_date(datetime),
           year = year(datetime)) |> 
    filter(parameter_value > 0, !is.na(date)) |> 
    group_by(date) |> 
    summarise(mean = mean(parameter_value, na.rm = TRUE),
             max = max(parameter_value, na.rm = TRUE),
             min = min(parameter_value, na.rm = TRUE)) |> 
  pivot_longer(mean:min, names_to = "statistic", values_to = "value") |>
  mutate(stream = "yuba river",
         gage_agency = "CDEC",
         gage_number = "YPB",
         parameter = "flow") |> 
  glimpse()

ggplot(yuba_format, aes(x = date, y = value)) +
  geom_line()

#Plotting butte and yuba flow
ggplot(yuba_regression_data_full, aes(x = yuba_flow_mean, y = butte_flow_mean)) +
  geom_point()

# combine butte and yuba together for regression modeling
yuba_format_wide <- yuba_format |> 
  ungroup() |> 
  select(-gage_agency, -gage_number) |> 
  pivot_wider(id_cols = c(stream, date), names_from = "statistic", values_from = "value", values_fill = NA) |> 
  filter(!is.na(date)) |> 
  glimpse()

yuba_regression_data_full <- yuba_format_wide |> 
  ungroup() |> 
  select(date, mean) |> 
  rename(yuba_flow_mean = mean) |> 
  full_join(butte_format_wide |> 
              select(date, mean) |> 
              rename(butte_flow_mean = mean)) |> 
  glimpse()

# FOR PREDICTIONS identify gaps to predict data
yuba_gap_mean <- yuba_regression_data_full |> 
  filter(is.na(yuba_flow_mean), !is.na(butte_flow_mean)) |> 
  rename(butte_flow = butte_flow_mean)

# FOR MODEL use data where there are no missing data for either butte or feather for regression modeling
yuba_regression_data_mean <- yuba_regression_data_full |> 
  filter(!is.na(yuba_flow_mean), !is.na(butte_flow_mean)) |> 
  rename(butte_flow = butte_flow_mean,
         flow = yuba_flow_mean)

#### Building Mean Regression
# MEAN Regression
split <-rsample::initial_split(yuba_regression_data_mean, prop = 0.8)
train <- rsample::training(split)
test <- rsample::testing(split)
yuba_mod_mean <- lm(flow ~ date + butte_flow, data = train)
summary(yuba_mod_mean)
test_predict <- predict(yuba_mod_mean, test)
test_predict_df <- test |>
  mutate(predicted = test_predict)
# evaluate predictions - MAPE of 10% is not bad
mean(abs((
  test_predict_df$predicted - test_predict_df$flow
)) / test_predict_df$flow)

# Predictions
yuba_gap_predicted_mean <- predict(yuba_mod_mean, yuba_gap_mean)
yuba_mean_predicted <- yuba_gap_mean |> 
  mutate(value = yuba_gap_predicted_mean,
         statistic = "mean_predicted") |> 
  filter(!is.na(date)) |> 
  select(date, value, statistic) |> 
  glimpse()

ggplot(yuba_mean_predicted, aes(x = date, y = value)) +
  geom_line()
  
#joining predictions to Yuba data
#Trimming predictions to only where data gaps exist (previous to 2011)
yuba_predicted_trimmed <- yuba_mean_predicted |> 
  filter(date <= "2011-01-31") |> 
  glimpse()

#checking that date range is now 1997-2024
range(yuba_predicted_trimmed$date)

# Left join to fill missing values in yuba_format_wide with values from yuba_mean_predicted
merged_data <- full_join(yuba_format_wide, yuba_predicted_trimmed, by = "date") |> 
  glimpse()

#mutating predicted and existing flow values into a single column
flow_modeled <- merged_data |> 
  mutate(flow = ifelse(is.na(mean), value, mean)) |> 
  select(c(stream, date, flow)) |> 
  glimpse()

#plotting flow data showing modeled and existing flow data 
ggplot(flow_modeled, aes(date, flow, color = date >= "2011-01-31")) +
  geom_line() +
  scale_color_manual(values = c("blue", "red"), labels = c("Modeled Flow Data", "YPB Flow Data")) +
  labs(color = "Flow Source") +
  theme_minimal()
```


```{r}
#Yuba gage option #2 -----

#USGS 11413517
# 2007-12-05	2024-03-20
# Gage Data

YUBA_USGS <- readNWISdv(11413517, "00060")

# Format to make tidier
yuba_usgs_daily_flows <- YUBA_USGS %>%
  select(Date, flow_cfs =  X_00060_00003) %>%
  as_tibble() %>% 
  rename(date = Date) |> 
  glimpse()

yuba_usgs_format <- yuba_usgs_daily_flows |> 
    filter(flow_cfs  > 0, !is.na(date)) |> 
    group_by(date) |> 
    summarise(mean = mean(flow_cfs , na.rm = TRUE),
             max = max(flow_cfs , na.rm = TRUE),
             min = min(flow_cfs , na.rm = TRUE)) |> 
  pivot_longer(mean:min, names_to = "statistic", values_to = "value") |>
  mutate(stream = "yuba river",
         gage_agency = "USGS",
         gage_number = "11413517",
         parameter = "flow") |> 
  glimpse()

ggplot(yuba_usgs_format, aes(x = date, y = value)) +
  geom_line()
# combine butte and yuba together for regression modeling
yuba_usgs_format_wide <- yuba_usgs_format |> 
  ungroup() |> 
  select(-gage_agency, -gage_number) |> 
  pivot_wider(id_cols = c(stream, date), names_from = "statistic", values_from = "value", values_fill = NA) |> 
  glimpse()

yuba_usgs_regression_data_full <- yuba_usgs_format_wide |> 
  ungroup() |> 
  select(date, mean) |> 
  rename(yuba_flow_mean = mean) |> 
  full_join(butte_format_wide |> 
              select(date, mean) |> 
              rename(butte_flow_mean = mean)) |> 
  glimpse()

# FOR PREDICTIONS identify gaps to predict data
yuba_usgs_gap_mean <- yuba_usgs_regression_data_full |> 
  filter(is.na(yuba_flow_mean), !is.na(butte_flow_mean)) |> 
  rename(butte_flow = butte_flow_mean)

# FOR MODEL use data where there are no missing data for either butte or feather for regression modeling
yuba_usgs_regression_data_mean <- yuba_usgs_regression_data_full |> 
  filter(!is.na(yuba_flow_mean), !is.na(butte_flow_mean)) |> 
  rename(butte_flow = butte_flow_mean,
         flow = yuba_flow_mean)

#### Building Mean Regression
# MEAN Regression
split <-rsample::initial_split(yuba_usgs_regression_data_mean, prop = 0.8)
train <- rsample::training(split)
test <- rsample::testing(split)
yuba_mod_mean <- lm(flow ~ date + butte_flow, data = train)
summary(yuba_mod_mean)
test_predict <- predict(yuba_mod_mean, test)
test_predict_df <- test |>
  mutate(predicted = test_predict)
# evaluate predictions - MAPE of 10% is not bad
mean(abs((
  test_predict_df$predicted - test_predict_df$flow
)) / test_predict_df$flow)

# Predictions
yuba_usgs_gap_predicted_mean <- predict(yuba_mod_mean, yuba_gap_mean)
yuba_usgs_mean_predicted <- yuba_gap_mean |> 
  mutate(value = yuba_usgs_gap_predicted_mean,
         statistic = "mean_predicted") |> 
  select(date, value, statistic)
ggplot(yuba_usgs_mean_predicted, aes(x = date, y = value)) +
  geom_line()


```

## Approach 3: Representative Stream and Scaling

**Benefit:**
**Limitation:**

Using a representative stream with available flow data can also be an effective approach. By selecting a stream with similar characteristics (e.g., drainage area, land use, climate), we can scale its flow data to estimate flows for the target stream.

### Example

```{r}
# Example R code for scaling



```


## Approach 4: Utilizing Existing Modeled Flow Data

**Benefit:** CalSim or SACWAM already modeled it for you, no need to repeat the process
**Limitation:** Montly flow granualarity may be limiting for your use case 

Existing modeled flow data from sources like Calsim or SACWAM can be utilized. Typically these modeled sources have already used an approach to fill data gaps. These models simulate hydrological processes and provide flow outputs, which can be directly used across the system. However, these modeled datasets are only available at a monthly timestep, additional modeling may be needed to produce finer scale flow data. 



## Approach 5: Expanding Existing Modeled Flow Data

**Benefit:**
**Limitation:**

If existing modeled flow data is available but lacks the required resolution, we can expand it to provide daily flow values. 

HOW? 

### Example

```{r}


```


